---
layout: post
title: Entropy trong lý thuyết thông tin
subtitle: Từ thống kê đến học máy
# color: turquoise
feature-img: assets/dl_posts/entropy/entropy4.jpg
excerpt_separator: 
categories: [Neural Networks]
tags: [statistics, machine learning, entropy, cross-entropy]
date: June 26, 2020 
comments: true
mathjax: true
---

**Nội dung bài viết**

* TOC
{:toc}

"Anything that can go wrong, will go wrong" - Murphy. [Murphy's law](https://en.wikipedia.org/wiki/Murphy%27s_law).

Tạm dịch: "Bất cứ thứ gì có thể trở nên tồi tệ, thì sẽ trở nên tồi tệ".

{% include aligner.html images="dl_posts/entropy/entropy2.png,dl_posts/entropy/entropy1.jpg" %}

Định luật trên là sự ám chỉ về xu hướng gây mất trật tự và làm mọi chuyện trở nên khó khăn trong đời sống của xã hội. Mọi vấn đề sẽ luôn phát sinh một cách tự nhiên lên chính bản thân của một người, muốn giải quyết vấn đề, nhất định phải cần năng lượng, trí tuệ, công sức, tiền bạc đổ vào đó. Cuộc sống không tự duy trì một cách hệ thống, mà có xu hướng ngày một trở nên phức tạp. Nếu không làm chủ được chính bản thân mình và điều hòa được cuộc sống, mọi thứ sẽ tệ dần đi theo thời gian.

Định luật trên thực sự là một vấn đề triết học, bao trùm lên nhiều ngành khoa học, nó đồng thời liên quan đến một trong những lực lượng lớn nhất trong vũ trụ, là căn bản của thế giới, là lực lượng chi phối cuộc đời mỗi con người, dẫn dắt nhiều vấn đề ta hay đối mặt và đương nhiên, nó đưa đến sự hỗn loạn: **entropy**.

Time to music: [Hỗn Độn](https://www.youtube.com/watch?v=52bqXTFRJfw).

# Sự ra đời của entropy

## Tên gọi entropy
Khi bắt đầu học về Machine Learning, tôi mới biết đến entropy thông qua một hàm số, gọi là cross-entropy mà lát nữa tôi sẽ đề cập. Thực sự thì khi tìm hiểu về entropy, tôi cũng rất mơ hồ vì khái niệm này quá lạ lẫm với tôi, có lẽ với những người học về vật lý lý thuyết thì sẽ quen hơn là những người làm toán. Lý do là vì entropy xuất hiện đầu tiên trong nhiệt động lực học, cụ thể: *"Lịch sử của entropy bắt đầu với công trình của nhà toán học người Pháp Lazare Carnot, quyển Các nguyên lý cơ bản của cân bằng và chuyển động (1803). Trong tác phẩm này, ông đã đề xuất nguyên lý cho rằng tất cả những sự gia tốc và va chạm của các phần đang chuyển động trong mọi cơ cấu đều có hiện diện của những hao tổn về "moment hoạt động". "* Chi tiết hơn, bạn có thể đọc ở [đây](https://vi.wikipedia.org/wiki/Entropy).

Theo tiếng Hy Lạp, “tropy” (τροπή ), có nghĩa là thay đổi, chuyển hướng, còn “en” có nghĩa là “bên trong”. Khi phiên âm sang tiếng Việt thì Entropy trở thành Ên-Trô-Pỳ. Như vậy, entropy là "kẻ gây ra sự xáo trộn, kẻ gây hỗn độn, hỗn loạn". Nếu coi vũ trụ này là một trường học thì entropy là học sinh cá biệt trong trường học đó.

 Nếu muốn tìm hiểu kĩ càng hơn, tôi rất khuyến khích bạn đọc bài báo [A Review of the Entropy Concept](https://arxiv.org/pdf/1711.07326.pdf#:~:text=Roots%20and%20genesis%20of%20the%20entropy%20concept&text=Two%20kinds%20of%20entropy%3B%20thermodynamic,above%20absolute%20zero%20%5B117%5D.), nó sẽ cho bạn một cái nhìn khoa học, trực diện và tổng quan về entropy. 

## Muôn hình vạn trạng của entropy

Vì sao việc dọn rửa nhà cửa lại phải diễn ra thường xuyên? Vì sao luôn có những kẻ ngáng chân trên con đường của bạn? Vì sao gia đình bạn thỉnh thoảng lại lục đục nội bộ? Vì sao trộm cắp ngày một nhiều dù cho xã hội "ngày một văn minh"?,... Câu trả lời chung nhất cho tất cả điều trên: Là vì entropy.

- Rất thú vị, trong một bài viết về văn hóa, tác giả PV. Hưng - một người thầy tôi ngưỡng mộ, đã viết về **entropy xã hội** là một kiểu mô tả những hỗn loạn ngày càng tăng trong xã hội loài người [(link bài viết)](https://viethungpham.com/2015/06/09/from-entropy-to-the-tao-tu-entropy-den-dao/).
Cũng trong bài viết trên, tác giả có nói đến hai định nghĩa thêm về entropy
    - Từ điển Dictionary of the English Language do Houghton Mifflin Harcourt xuất bản tại Mỹ năm 2011, đưa ra 5 định nghĩa của entropy, trong đó có định nghĩa sau đây: “Entropy: Inevitable and steady deterioration of a system or society” (Entropy: Sự suy thoái chắc chắn và không thể tránh khỏi của một hệ thống hoặc một xã hội).
    - Từ điển Random House Kernerman Webster’s College đưa ra 4 định nghĩa, trong đó định nghĩa thứ 4 viết: “Entropy: a state of disorder, as in a social system, or a hypothetical tendency toward such a state” (Entropy: một trạng thái hỗn loạn, như trong một hệ thống xã hội, hoặc một xu thế được cho là hướng tới một trạng thái như thế).

Thực sự thì bài viết trên quá xuất sắc nên tôi cũng không đi sâu thêm nữa, bạn hãy đọc và tự cảm nhận. Tôi sẽ chỉ đưa thêm ba loại entropy dưới đây
- **entropy trong nhiệt động lực học**, ký hiệu là \\(\displaystyle S\\), là một đơn vị đo nhiệt năng phát tán, hấp thụ khi một hệ vật lý chuyển trạng thái tại một nhiệt độ tuyệt đối xác định.
\\[dS = \dfrac{\partial Q}{T},\\] trong đó \\(S\\) là độ lớn của entropy, \\(dS\\) là sự thay đổi độ lớn của entropy, \\(T\\) là nhiệt độ tuyệt đối, còn \\(\partial Q\\) là độ thay đổi nhiệt năng của hệ.

Theo [định luật 2 nhiệt động lực học](https://vi.wikipedia.org/wiki/%C4%90%E1%BB%8Bnh_lu%E1%BA%ADt_hai_nhi%E1%BB%87t_%C4%91%E1%BB%99ng_l%E1%BB%B1c_h%E1%BB%8Dc), nơi nhận được nhiệt đó phải lạnh hơn là vật ban đầu nếu ta không muốn tiêu thêm năng lượng vào đó. Như vậy, entropy của vũ trụ này luôn tăng theo thời gian. Đây cũng là một trong những lí lẽ để bảo chứng rằng **không bao giờ có chuyện tạo ra được cỗ máy thời gian quay về quá khứ**, hay thời gian đảo ngược, vì đơn giản là entropy không ngừng tăng.
Ngoài ra, việc entropy luôn luôn "ăn" năng lượng hữu ích, sẽ dẫn đến trạng thái **maximal entropy**, lúc đó sẽ không còn năng lượng có thể sử dụng được, dẫn đến giả thuyết *cái chết nhiệt*, hay [heat death](https://en.wikipedia.org/wiki/Heat_death_of_the_universe). Cần phải xác thực rằng entropy không phải là một dạng năng lượng, nó chỉ "ăn" năng lượng và liên tục lớn lên.

Một ví dụ tiêu biểu, tủ lạnh hút nhiệt bên trong tủ thổi ra ngoài, làm bên trong thì lạnh đi, còn bên ngoài nóng lên. Entropy chỉ cho phép tủ lạnh hay máy điều hòa làm lạnh với điều kiện là phải cung cấp cho nó năng lượng: Khi máy điều hòa làm giảm nhiệt năng trong phòng, thì làm tăng nhiệt năng ngoài trời một lượng nhiều hơn là lượng giảm đi trong phòng, và độ chênh lệch giữa hai lượng chính là lượng điện năng mà máy tiêu thụ. Nhiệt độ ngoài trời mà càng cao hơn bên trong nhà, thì càng phải "feed" nhiều điện năng cho Entropy, khi đó mới được phép thổi nhiệt ngược từ chỗ lạnh trong nhà ra chỗ nóng ngoài trời.
- **entropy trong cơ học thống kê** được định nghĩa như là một đơn vị đo lường khả năng mà một hệ có thể rơi vào trạng thái hỗn độn trong một tình trạng, nó thường được gọi là "sự lộn xộn" hay "tính bừa" thể hiện trong một hệ.
- Trong kinh tế, khái niệm **corporate entropy** để chỉ sự rắm rối của các doanh nghiệp dẫn đến giảm hiệu quả lao động.
- Loại cuối cùng, cũng chính là chủ đạo trong bài viết này: [Entropy trong lí thuyết thông tin](https://vi.wikipedia.org/wiki/Entropy_th%C3%B4ng_tin)

# Entropy trong lý thuyết thông tin

Lý thuyết thông tin (Information Theory) là một nhánh toán ứng dụng quan tâm đến các vấn đề định lượng (quantification), lưu trữ (storage) và truyền dẫn dữ liệu (communication) của thông tin. Thông tin là một khái niệm trừu tượng (không phải một thực thể lý tính) do đó khó mà định lượng thông tin theo cách thông thường, chúng ta cần những độ đo phù hợp để định lượng chúng.

Xét ví dụ sau
> 










# Tài liệu tham khảo
1. [ly-thuyet-thong-tin](https://thetalog.com/statistics/ly-thuyet-thong-tin/)

2. [entropy-information-theory](https://en.wikipedia.org/wiki/Entropy_(information_theory))

3. [entropy-zung.zetamu.net](http://zung.zetamu.net/2010/09/entropy/#:~:text=Theo%20g%E1%BB%91c%20Hy%20L%E1%BA%A1p%2C%20%E2%80%9Ctropy,ch%E1%BB%AF%20tr%C3%B4%20%C4%91%E1%BB%8Dc%20ch%E1%BB%9D%20n%E1%BA%B7ng).&text=T%E1%BB%AB%20%C4%91%C3%B3%20t%C3%B4i%20c%E1%BB%A9%20n%C3%B3i,En%20Tr%C3%B4%20P%E1%BB%B3%20ho%C3%A0nh%20h%C3%A0nh.)

4. [Entropy, Cross Entropy, KL Divergence](https://thetalog.com/statistics/ly-thuyet-thong-tin/)